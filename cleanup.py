import os
import datetime
import csv
import re

# ==========================================
# ì„¤ì •
# ==========================================
RETENTION_DAYS = 90  # 90ì¼(3ê°œì›”) ë³´ê´€
REPORTS_DIR = "reports"
BACKUP_DIR = "backups"

def cleanup_old_reports():
    print("ğŸ§¹ ì˜¤ë˜ëœ ë¦¬í¬íŠ¸ ì •ë¦¬ ì‹œì‘...")
    
    if not os.path.exists(REPORTS_DIR):
        print("âŒ reports í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if not os.path.exists(BACKUP_DIR):
        os.makedirs(BACKUP_DIR)

    now = datetime.datetime.now()
    cutoff_date = now - datetime.timedelta(days=RETENTION_DAYS)
    
    # ì‚­ì œí•  íŒŒì¼ ëª©ë¡ ì°¾ê¸°
    files_to_archive = []
    for filename in os.listdir(REPORTS_DIR):
        if not filename.endswith(".html"): continue
        
        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (20251229_1400.html)
        try:
            date_str = filename.split("_")[0] # 20251229
            file_date = datetime.datetime.strptime(date_str, "%Y%m%d")
            
            if file_date < cutoff_date:
                files_to_archive.append(filename)
        except:
            continue # ë‚ ì§œ í˜•ì‹ì´ ì•ˆ ë§ìœ¼ë©´ íŒ¨ìŠ¤

    if not files_to_archive:
        print("âœ… ì‚­ì œí•  ì˜¤ë˜ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“¦ {len(files_to_archive)}ê°œì˜ íŒŒì¼ì„ ë°±ì—…í•˜ê³  ì‚­ì œí•©ë‹ˆë‹¤...")

    # CSV íŒŒì¼ëª… (ì˜ˆ: backup_2025-01.csv)
    backup_filename = f"{BACKUP_DIR}/backup_{now.strftime('%Y-%m')}.csv"
    file_exists = os.path.isfile(backup_filename)

    with open(backup_filename, "a", newline="", encoding="utf-8-sig") as csvfile:
        fieldnames = ["date", "keyword", "count", "grade"]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        if not file_exists:
            writer.writeheader()

        for filename in files_to_archive:
            filepath = os.path.join(REPORTS_DIR, filename)
            
            # HTML íŒŒì¼ ì½ì–´ì„œ ë°ì´í„° ì¶”ì¶œ (ê°„ë‹¨ íŒŒì‹±)
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read()
            
            # ì •ê·œì‹ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ (í…Œì´ë¸” í–‰)
            # <tr>...<span class="keyword-text">í‚¤ì›Œë“œ</span>...<td class="count-cell">1,234ê±´</td>...</tr>
            matches = re.findall(r'<span class="keyword-text">([^<]+)</span>.*?class="count-cell">([^<]+)ê±´</td>.*?<span class="badge">([^<]+)</span>', content, re.DOTALL)
            
            file_time = filename.replace(".html", "")
            
            for match in matches:
                writer.writerow({
                    "date": file_time,
                    "keyword": match[0],
                    "count": match[1],
                    "grade": match[2]
                })
            
            # ì›ë³¸ íŒŒì¼ ì‚­ì œ
            os.remove(filepath)
            print(f"ğŸ—‘ï¸ ì‚­ì œë¨: {filename}")

    print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_filename}")

if __name__ == "__main__":
    cleanup_old_reports()
